{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNuipBPRBx4vAdlVWic3SL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericslevenson/arctic-surface-water/blob/main/LakeTimeSeriesv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGgPxn5kJfmq"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "author: @ericslevenson\n",
        "date: 11/28/2022\n",
        "description: GEE script to export near-daily records of lake area within a\n",
        "shapefile of buffered lakes\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate private account (only required for exporting to drive/gee/gcp)\n",
        "from google.colab import auth \n",
        "auth.authenticate_user()\n",
        "\n",
        "# Earth Engine setup\n",
        "import ee # Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "ee.Initialize() # Initialize the library.\n",
        "\n",
        "# Google Drive setup (if needed)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "K1xZzHHaKB0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84326131-a4c6-4a3b-f287-fdc4f26d9eab"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=8SZ1VVtQIlB4PFV9YaYA6POD86WVbLd1ZSee8EOrIdM&tc=r5Cps0HezgRH-st0MAAlUJpHgKRnwIFnj2tZInje7rU&cc=88_ezgBWXv4iy00aJacubYBWmkHBVDi0Cf-ny5J4AIw\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1AfgeXvtbsyqdagMjsvTGrnCBaPNzbuV174GagU68XAZELIEmlWroNP-HBAk\n",
            "\n",
            "Successfully saved authorization token.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ***INPUTS***\n",
        "\n",
        "## Regularly Adjusted inputs ##\n",
        "\n",
        "# Time Period\n",
        "start = '2018-05-01'\n",
        "finish = '2019-09-30'\n",
        "\n",
        "# Tile of interest\n",
        "tile = 10\n",
        "\n",
        "# Lake Shapefile\n",
        "lakes = ee.FeatureCollection('projects/ee-eric-levenson/assets/AGU_transect/04transect_tsSeed_dissolved')\n",
        "\n",
        "\n",
        "## Periodically Adjusted Inputs ##\n",
        "# ROI tile collection\n",
        "tiles = ee.FeatureCollection('projects/ee-eric-levenson/assets/AGU_transect/transect_tiles')\n",
        "\n",
        "## Rarely Adjusted inputs ##\n",
        "# Image scale\n",
        "pixScale = 10\n",
        "\n",
        "# ***EXPORTS***\n",
        "\n",
        "# Export Properties\n",
        "exportSelectors = ['id', 'FID', 'waterArea', 'allPixels', 'clearArea', 'clearPixels', 'cloudArea', 'cloudPixels', 'centroid', 'ratio'] # These will likely need to be changed to reflect your input shapefile. Specifically, 'count', 'centroid', and 'ratio' are all attributes from the imported EE asset. The others can stay the same.\n",
        "# ROI Description\n",
        "roiLabel = str('04transect_'+str(tile))\n",
        "# Export Folder\n",
        "exportFolder = 'AGU'\n",
        "\n",
        "# ***EARTH ENGINE-IFY***\n",
        "eestart = ee.Date(start)\n",
        "eefinish = ee.Date(finish)\n",
        "startDoy = ee.Date(start).getRelative('day', 'year')\n",
        "endDoy = ee.Date(finish).getRelative('day', 'year')\n",
        "eeroi = tiles.filter(ee.Filter.eq('id', tile)).first()\n",
        "roi = ee.Geometry.Polygon(eeroi.geometry().getInfo()['coordinates'][0]) \n",
        "lakes = lakes.filterBounds(roi) # filter lakes to roi"
      ],
      "metadata": {
        "id": "I3GpdMVWKFzj"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "Kt-UVUejLtzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ***IMAGE PRE-PROCESSING METHODS***\n",
        "\n",
        "# Mask clouds in Sentinel-2\n",
        "def maskS2clouds(image):\n",
        "  '''Takes an input and adds two bands: cloud mask and clear mask'''\n",
        "  qa = image.select('QA60')\n",
        "  cloudBitMask = 1 << 10\n",
        "  cirrusBitMask = 1 << 11\n",
        "  clear_mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0)).rename('clear_mask')\n",
        "  cloud_mask = qa.bitwiseAnd(cloudBitMask).eq(1).And(qa.bitwiseAnd(cirrusBitMask).eq(1)).rename('cloud_mask')\n",
        "  return image.addBands([cloud_mask,clear_mask])\n",
        "\n",
        "# Clip image\n",
        "def clip_image(image):\n",
        "  '''Clips to the roi defined at the beginning of the script'''\n",
        "  return image.clip(roi)\n",
        "\n",
        "def clip2lakes(image):\n",
        "  '''Clips an image based on the lake boundaries'''\n",
        "  return image.clip(lakes)\n",
        "\n",
        "# Get percentile cover   \n",
        "def getCover(image):\n",
        "  '''calculates percentage of the roi covered by the clear mask. NOTE: this function\n",
        "  calls the global totPixels variable that needs to be calculated in the main script.'''\n",
        "  actArea = ee.Number(image.updateMask(image.select('B2')).reduceRegion(\n",
        "      reducer = ee.Reducer.count(),\n",
        "      scale = 100,\n",
        "      maxPixels=1e12,\n",
        "      ).values().get(0)).multiply(10000)\n",
        "  # calculate the perc of cover OF CLEAR PIXELS \n",
        "  percCover = actArea.divide(area).multiply(100)\n",
        "  # number as output\n",
        "  return image.set('percCover', percCover,'actArea',actArea)\n",
        "  \n",
        "# Mosaic images by date, orbit, - basically combines images together that were taken on the same day \n",
        "def mosaicBy(imcol):\n",
        "  '''Takes an image collection (imcol) and creates a mosaic for each day\n",
        "  Returns: An image collection of daily mosaics'''\n",
        "  #return the collection as a list of images (not an image collection)\n",
        "  imlist = imcol.toList(imcol.size())\n",
        "  # Get all the dates as list\n",
        "  def imdate(im):\n",
        "    date = ee.Image(im).date().format(\"YYYY-MM-dd\")\n",
        "    return date\n",
        "  all_dates = imlist.map(imdate)\n",
        "  # get all orbits as list\n",
        "  def orbitId(im):\n",
        "    orb = ee.Image(im).get('SENSING_ORBIT_NUMBER')\n",
        "    return orb\n",
        "  all_orbits = imlist.map(orbitId)\n",
        "  # get all spacecraft names as list\n",
        "  def spacecraft(im):\n",
        "    return ee.Image(im).get('SPACECRAFT_NAME')\n",
        "  all_spNames = imlist.map(spacecraft)\n",
        "  # this puts dates, orbits and names into a nested list\n",
        "  concat_all = all_dates.zip(all_orbits).zip(all_spNames);\n",
        "  # here we unnest the list with flatten, and then concatenate the list elements with \" \"\n",
        "  def concat(el):\n",
        "    return ee.List(el).flatten().join(\" \")\n",
        "  concat_all = concat_all.map(concat)\n",
        "  # here, just get distinct combintations of date, orbit and name\n",
        "  concat_unique = concat_all.distinct()\n",
        "  # mosaic\n",
        "  def mosaicIms(d):\n",
        "    d1 = ee.String(d).split(\" \")\n",
        "    date1 = ee.Date(d1.get(0))\n",
        "    orbit = ee.Number.parse(d1.get(1)).toInt()\n",
        "    spName = ee.String(d1.get(2))\n",
        "    im = imcol.filterDate(date1, date1.advance(1, \"day\")).filterMetadata('SPACECRAFT_NAME', 'equals', spName).filterMetadata('SENSING_ORBIT_NUMBER','equals', orbit).mosaic()\n",
        "    return im.set(\n",
        "        \"system:time_start\", date1.millis(),\n",
        "        \"system:date\", date1.format(\"YYYY-MM-dd\"),\n",
        "        \"system:id\", d1)\n",
        "  mosaic_imlist = concat_unique.map(mosaicIms)\n",
        "  return ee.ImageCollection(mosaic_imlist)\n",
        "\n",
        "###########################################################################\n",
        "## ***WATER CLASSIFICATION METHODS***\n",
        "\n",
        "# Define NDWI image\n",
        "def ndwi(image):\n",
        "  '''Adds an NDWI band to the input image'''\n",
        "  return image.normalizedDifference(['B3', 'B8']).rename('NDWI').multiply(1000)\n",
        "\n",
        "# Basic ndwi classification  \n",
        "def ndwi_classify(image):\n",
        "  '''Creates a binary image based on an NDWI threshold of 0'''\n",
        "  ndwimask = image.select('NDWI')\n",
        "  water = ndwimask.gte(0)\n",
        "  land = ndwimask.lt(0)\n",
        "  return(water)\n",
        "\n",
        "# OTSU thresholding from histogram\n",
        "def otsu(histogram):\n",
        "  '''Returns the NDWI threshold for binary water classification'''\n",
        "  counts = ee.Array(ee.Dictionary(histogram).get('histogram'))\n",
        "  means = ee.Array(ee.Dictionary(histogram).get('bucketMeans'))\n",
        "  size = means.length().get([0])\n",
        "  total = counts.reduce(ee.Reducer.sum(), [0]).get([0])\n",
        "  sum = means.multiply(counts).reduce(ee.Reducer.sum(), [0]).get([0])\n",
        "  mean = sum.divide(total)\n",
        "  indices = ee.List.sequence(1, size)\n",
        "  def func_xxx(i):\n",
        "    '''Compute between sum of squares, where each mean partitions the data.'''\n",
        "    aCounts = counts.slice(0, 0, i)\n",
        "    aCount = aCounts.reduce(ee.Reducer.sum(), [0]).get([0])\n",
        "    aMeans = means.slice(0, 0, i)\n",
        "    aMean = aMeans.multiply(aCounts) \\\n",
        "        .reduce(ee.Reducer.sum(), [0]).get([0]) \\\n",
        "        .divide(aCount)\n",
        "    bCount = total.subtract(aCount)\n",
        "    bMean = sum.subtract(aCount.multiply(aMean)).divide(bCount)\n",
        "    return aCount.multiply(aMean.subtract(mean).pow(2)).add(\n",
        "           bCount.multiply(bMean.subtract(mean).pow(2)))\n",
        "  bss = indices.map(func_xxx)\n",
        "  # Return the mean value corresponding to the maximum BSS.\n",
        "  return means.sort(bss).get([-1])\n",
        "\n",
        "# OTSU thresholding for an image\n",
        "def otsu_thresh(water_image):\n",
        "  '''Calculate NDWI and create histogram. Return the OTSU threshold.'''\n",
        "  NDWI = ndwi(water_image).select('NDWI').updateMask(water_image.select('clear_mask'))\n",
        "  histogram = ee.Dictionary(NDWI.reduceRegion(\n",
        "    geometry = roi,\n",
        "    reducer = ee.Reducer.histogram(255, 2).combine('mean', None, True).combine('variance', None, True),\n",
        "    scale = pixScale,\n",
        "    maxPixels = 1e12\n",
        "  ))\n",
        "  return otsu(histogram.get('NDWI_histogram'))\n",
        "\n",
        "# Classify an image using OTSU threshold.\n",
        "def otsu_classify(water_image):\n",
        "  '''(1) Calculate NDWI and create histogram. (2) Calculate NDWI threshold for \n",
        "  binary classification using OTSU method. (3) Classify image and add layer to input image.\n",
        "  '''\n",
        "  NDWI = ndwi(water_image).select('NDWI')\n",
        "  histogram = ee.Dictionary(NDWI.reduceRegion(\n",
        "    geometry = roi,\n",
        "    reducer = ee.Reducer.histogram(255, 2).combine('mean', None, True).combine('variance', None, True),\n",
        "    scale = pixScale,\n",
        "    maxPixels = 1e12\n",
        "  ))\n",
        "  threshold = otsu(histogram.get('NDWI_histogram'))\n",
        "  otsu_classed = NDWI.gt(ee.Number(threshold)).And(water_image.select('B8').lt(2000)).rename('otsu_classed')\n",
        "  return water_image.addBands([otsu_classed])\n",
        "\n",
        "def adaptive_thresholding(water_image):\n",
        "  '''Takes an image clipped to lakes and returns the water mask'''\n",
        "  NDWI = ndwi(water_image).select('NDWI')#.updateMask(water_image.select('clear_mask')) # get NDWI **TURNED OFF CLOUD MASK, SHOULD THIS STAY OFF?**\n",
        "  threshold = ee.Number(otsu_thresh(water_image)) \n",
        "  threshold = threshold.divide(10).round().multiply(10)\n",
        "  # get fixed histogram\n",
        "  histo = NDWI.reduceRegion(\n",
        "      geometry = roi,\n",
        "      reducer = ee.Reducer.fixedHistogram(-1000, 1000, 200),\n",
        "      scale = pixScale, # This was 30, keep at 10!?!?\n",
        "      maxPixels = 1e12\n",
        "  )\n",
        "  hist = ee.Array(histo.get('NDWI'))\n",
        "  counts = hist.cut([-1,1])\n",
        "  buckets = hist.cut([-1,0])\n",
        "  #find split points from otsu threshold\n",
        "  threshold = ee.Array([threshold]).toList()\n",
        "  buckets_list = buckets.toList()\n",
        "  split = buckets_list.indexOf(threshold)\n",
        "  # split into land and water slices\n",
        "  land_slice = counts.slice(0,0,split)\n",
        "  water_slice = counts.slice(0,split.add(1),-1)\n",
        "  # find max of land and water slices\n",
        "  land_max = land_slice.reduce(ee.Reducer.max(),[0])\n",
        "  water_max = water_slice.reduce(ee.Reducer.max(),[0])\n",
        "  land_max = land_max.toList().get(0)\n",
        "  water_max = water_max.toList().get(0)\n",
        "  land_max = ee.List(land_max).getNumber(0)\n",
        "  water_max = ee.List(water_max).getNumber(0)\n",
        "  #find difference between land, water and otsu val\n",
        "  counts_list = counts.toList()\n",
        "  otsu_val = ee.Number(counts_list.get(split))\n",
        "  otsu_val = ee.List(otsu_val).getNumber(0)\n",
        "  land_prom = ee.Number(land_max).subtract(otsu_val)\n",
        "  water_prom = ee.Number(water_max).subtract(otsu_val)\n",
        "  #find land and water buckets corresponding to 0.9 times the prominence\n",
        "  land_thresh = ee.Number(land_max).subtract((land_prom).multiply(ee.Number(0.9)))\n",
        "  water_thresh = ee.Number(water_max).subtract((water_prom).multiply(ee.Number(0.9)))\n",
        "  land_max_ind = land_slice.argmax().get(0)\n",
        "  water_max_ind = water_slice.argmax().get(0)\n",
        "  li = ee.Number(land_max_ind).subtract(1)\n",
        "  li = li.max(ee.Number(1))\n",
        "  wi = ee.Number(water_max_ind).add(1)\n",
        "  wi = wi.min(ee.Number(199))\n",
        "  land_slice2 = land_slice.slice(0,li,-1).subtract(land_thresh)\n",
        "  water_slice2 = water_slice.slice(0,0,wi).subtract(water_thresh)\n",
        "  land_slice2  = land_slice2.abs().multiply(-1)\n",
        "  water_slice2 = water_slice2.abs().multiply(-1)\n",
        "  land_index = ee.Number(land_slice2.argmax().get(0)).add(land_max_ind)\n",
        "  water_index = ee.Number(water_slice2.argmax().get(0)).add(split)\n",
        "  land_level = ee.Number(buckets_list.get(land_index))\n",
        "  water_level = ee.Number(buckets_list.get(water_index))\n",
        "  land_level = ee.Number(ee.List(land_level).get(0)).add(5)\n",
        "  water_level = ee.Number(ee.List(water_level).get(0)).add(5)\n",
        "  #calculate water fraction and classify\n",
        "  water_fraction = (NDWI.subtract(land_level)).divide(water_level.subtract(land_level)).multiply(100).rename('water_fraction')\n",
        "  #water_fraction = conditional(water_fraction) #sets values less than 0 to 0 and greater than 100 to 100\n",
        "  water_75 = water_fraction.gte(75).rename('water_75'); #note, this is a non-binary classification, so we use 75% water as \"water\"\n",
        "  all_mask = water_image.select('B2').gt(5).rename('all_mask')\n",
        "  cloud_mask_ed = water_image.select('clear_mask').neq(1).rename('cloud_mask_ed')\n",
        "  return water_image.addBands([water_fraction,water_75,NDWI,cloud_mask_ed])\n",
        "# Apply cloud mask to other bands\n",
        "def applyMask(image):\n",
        "  img = image.updateMask(image.select('clear_mask'))\n",
        "  return img\n",
        "def binaryImage(image):\n",
        "  '''takes a multiband image and returns just the binary water_75 band'''\n",
        "  img = image.select('water_75')\n",
        "  return img\n",
        "def waterImage(image):\n",
        "  '''takes a multiband image and returns just the water fraction band'''\n",
        "  img = image.select('water_fraction')\n",
        "  return img\n",
        "\n",
        "###############################################################################\n",
        "## ***PROPERTY EXTRACTION METHODS***\n",
        "def sumWater(lake):\n",
        "  '''sums the water pixels within a buffered lake polygon and adds the result to the feature'''\n",
        "  watersum = waterAreaIm.select('area').reduceRegion(\n",
        "      reducer=ee.Reducer.sum(),\n",
        "      geometry = lake.geometry(),\n",
        "      scale = 10,\n",
        "      maxPixels=1e9\n",
        "  ).get('area')\n",
        "  return watersum\n",
        "\n",
        "def sumClear(lake):\n",
        "  '''sums the number of clear pixels within a buffered lake polygon'''\n",
        "  clearsum = lakeIm.select('clear_mask').reduceRegion(\n",
        "      reducer=ee.Reducer.sum(),\n",
        "      geometry = lake.geometry(),\n",
        "      scale = 10,\n",
        "      maxPixels=1e9\n",
        "  ).get('clear_mask')\n",
        "  return clearsum\n",
        "\n",
        "def getClearArea(lake):\n",
        "  '''trying what i did with water...see if it works! Will potentialy switch for sumClear'''\n",
        "  clearArea = clearAreaIm.select('area').reduceRegion(\n",
        "      reducer=ee.Reducer.sum(),\n",
        "      geometry = lake.geometry(),\n",
        "      scale = 10,\n",
        "      maxPixels=1e9\n",
        "  ).get('area')\n",
        "  return clearArea\n",
        "\n",
        "def sumClouds(lake):\n",
        "  '''sums the number of clear pixels within a buffered lake polygon'''\n",
        "  cloudsum = lakeIm.select('cloud_mask_ed').reduceRegion(\n",
        "      reducer=ee.Reducer.sum(),\n",
        "      geometry = lake.geometry(),\n",
        "      scale = 10,\n",
        "      maxPixels=1e9\n",
        "  ).get('cloud_mask_ed')\n",
        "  return cloudsum\n",
        "\n",
        "def getCloudArea(lake):\n",
        "  '''trying what i did with water...see if it works! Will potentialy switch for sumClouds'''\n",
        "  cloudArea = cloudAreaIm.select('area').reduceRegion(\n",
        "      reducer=ee.Reducer.sum(),\n",
        "      geometry = lake.geometry(),\n",
        "      scale = 10,\n",
        "      maxPixels=1e9\n",
        "  ).get('area')\n",
        "  return cloudArea\n",
        "\n",
        "def sumAll(lake):\n",
        "  '''sums the number of pixels within a buffered lake polygon'''\n",
        "  all_mask = lakeIm.select('B2').gt(5).rename('all_mask')\n",
        "  allsum = all_mask.reduceRegion(\n",
        "      reducer=ee.Reducer.count(),\n",
        "      geometry = lake.geometry(),\n",
        "      scale = 10,\n",
        "      maxPixels=1e9\n",
        "      ).get('all_mask')\n",
        "  return allsum  \n",
        "\n",
        "def troid(lake):\n",
        "  center = ee.Array(lake.centroid().geometry().coordinates())\n",
        "  return center\n",
        "\n",
        "def getID(lake):\n",
        "  '''get the EarthEngine id'''\n",
        "  id = ee.Number(lake.id())\n",
        "  return id\n",
        "\n",
        "def getFID(lake):\n",
        "  '''get the FID field from shapefile'''\n",
        "  fid = ee.Number(lake.get('FID'))\n",
        "  return fid\n",
        "\n",
        "#def getCount(lake):\n",
        "#  count = ee.Number(lake.get('count'))\n",
        "#  return count\n",
        "\n",
        "\n",
        "def lakeProps(lake):\n",
        "  water = sumWater(lake)\n",
        "  clear = sumClear(lake)\n",
        "  clouds = sumClouds(lake)\n",
        "  all = sumAll(lake)\n",
        "  centroid = troid(lake)\n",
        "  id = getID(lake)\n",
        "  #count = getCount(lake)\n",
        "  #label = getLabel(lake)\n",
        "  fid = getFID(lake)\n",
        "  cloudArea = getCloudArea(lake)\n",
        "  clearArea = getClearArea(lake)\n",
        "  return ee.Feature(None, {'id': id, 'FID': fid, 'waterArea': water, 'clearPixels': clear, 'clearArea': clearArea, 'cloudPixels': clouds, 'cloudArea': cloudArea, 'allPixels': all, 'centroid': centroid})\n",
        "\n",
        "###############################################################################\n",
        "## ***EXPORT METHODS***\n",
        "def export_lakes(collection, description, fileNamePrefix, fileFormat, folder, selectors):\n",
        "  '''Export a feature collection of lake properties to google drive for a given day.'''\n",
        "  task = ee.batch.Export.table.toDrive(**{\n",
        "    'collection': collection,\n",
        "    'description': description, \n",
        "    'fileNamePrefix': fileNamePrefix,\n",
        "    'fileFormat': fileFormat,\n",
        "    'folder': folder,\n",
        "    'selectors': selectors\n",
        "  })\n",
        "  task.start()"
      ],
      "metadata": {
        "id": "A6D112FJLqXV"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "iodnIKGsLvl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "## *** IMAGE PROCESSING ***\n",
        "images = ee.ImageCollection('COPERNICUS/S2').filterBounds(roi).filterDate(start,finish).filter(ee.Filter.calendarRange(startDoy, endDoy, 'day_of_year')).filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',50)) # Get Images\n",
        "images_all = mosaicBy(images) # Mosaic images\n",
        "images_all = images_all.map(maskS2clouds) # Create cloud/clear masks\n",
        "images_all = images_all.map(clip_image) # Clip to roi\n",
        "images_all.map(applyMask) # mask other bands for clouds\n",
        "area = roi.area().getInfo() # Calculate total area\n",
        "# Filter by percentile cover\n",
        "images_all = images_all.map(getCover) # Add percent cover as an image property\n",
        "images_all = images_all.filterMetadata('percCover','greater_than',10) # remove images covering less than 50% of the ROI)\n",
        "lakeimages = images_all.map(clip2lakes) # Clip images to buffered lake mask\n",
        "dates = lakeimages.aggregate_array('system:date').getInfo()\n",
        "\n",
        "###############################################################################\n",
        "## ***WATER CLASSIFICATION***\n",
        "lakeimages = lakeimages.map(adaptive_thresholding)\n",
        "\n",
        "###############################################################################\n",
        "## ***ITERATE THROUGH DAYS AND EXPORT***\n",
        "for i, date in enumerate(dates):\n",
        "  # Get lake properties\n",
        "  eedate = ee.Date(date) #earthengine date format\n",
        "  lakeIm = lakeimages.filterDate(eedate).first() # get the appropriate date\n",
        "  areaIm = lakeIm.pixelArea() # get a pixel area image\n",
        "  lakeIm = lakeIm.addBands([areaIm]) # add pixel area as a band in the image\n",
        "  waterAreaIm = areaIm.updateMask(lakeIm.select('water_75')) # mask area image based on water\n",
        "  cloudAreaIm = areaIm.updateMask(lakeIm.select('cloud_mask_ed')) # mask area image based on clouds\n",
        "  clearAreaIm = areaIm.updateMask(lakeIm.select('clear_mask')) # mask area image based on clearness\n",
        "  lakes2 = lakes.map(lakeProps)\n",
        "  # Export\n",
        "  exportDate = date.replace('-', '_')\n",
        "  description = roiLabel +'_'+ exportDate\n",
        "  fileformat = 'CSV'\n",
        "  export_lakes(lakes2, description, description, fileformat, exportFolder, exportSelectors)"
      ],
      "metadata": {
        "id": "1Aa0IdrpL9tu"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Same main script, split out to inspect dates before export'''\n",
        "\n",
        "##############################################################################\n",
        "## *** IMAGE PROCESSING ***\n",
        "images = ee.ImageCollection('COPERNICUS/S2').filterBounds(roi).filterDate(start,finish).filter(ee.Filter.calendarRange(startDoy, endDoy, 'day_of_year')).filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',50)) # Get Images\n",
        "images_all = mosaicBy(images) # Mosaic images\n",
        "images_all = images_all.map(maskS2clouds) # Create cloud/clear masks\n",
        "images_all = images_all.map(clip_image) # Clip to roi\n",
        "images_all.map(applyMask) # mask other bands for clouds\n",
        "area = roi.area().getInfo() # Calculate total area\n",
        "# Filter by percentile cover\n",
        "images_all = images_all.map(getCover) # Add percent cover as an image property\n",
        "images_all = images_all.filterMetadata('percCover','greater_than',10) # remove images covering less than 50% of the ROI)\n",
        "lakeimages = images_all.map(clip2lakes) # Clip images to buffered lake mask\n",
        "dates = lakeimages.aggregate_array('system:date').getInfo()\n",
        "print(dates)"
      ],
      "metadata": {
        "id": "heuw1Juc2btY"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "## ***WATER CLASSIFICATION***\n",
        "lakeimages = lakeimages.map(adaptive_thresholding)\n",
        "\n",
        "###############################################################################\n",
        "## ***ITERATE THROUGH DAYS AND EXPORT***\n",
        "for i, date in enumerate(dates):\n",
        "  # Get lake properties\n",
        "  eedate = ee.Date(date) #earthengine date format\n",
        "  lakeIm = lakeimages.filterDate(eedate).first() # get the appropriate date\n",
        "  areaIm = lakeIm.pixelArea() # get a pixel area image\n",
        "  lakeIm = lakeIm.addBands([areaIm]) # add pixel area as a band in the image\n",
        "  waterAreaIm = areaIm.updateMask(lakeIm.select('water_75')) # mask area image based on water\n",
        "  cloudAreaIm = areaIm.updateMask(lakeIm.select('cloud_mask_ed')) # mask area image based on clouds\n",
        "  clearAreaIm = areaIm.updateMask(lakeIm.select('clear_mask')) # mask area image based on clearness\n",
        "  lakes2 = lakes.map(lakeProps)\n",
        "  # Export\n",
        "  exportDate = date.replace('-', '_')\n",
        "  description = roiLabel +'_'+ exportDate\n",
        "  fileformat = 'CSV'\n",
        "  export_lakes(lakes2, description, description, fileformat, exportFolder, exportSelectors)"
      ],
      "metadata": {
        "id": "98zfNETwTzLg"
      },
      "execution_count": 60,
      "outputs": []
    }
  ]
}